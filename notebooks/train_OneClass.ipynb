{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import pca\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "norm_data = pd.read_csv(\"../csv/expanded_dataset_norm_v1.csv\")\n",
    "data = norm_data.drop(['Class'], axis=1)\n",
    "target = norm_data['Class']\n",
    "norm_data = norm_data.drop(norm_data.columns[[0,]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.73359073359073357, 0.81725888324873097)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.57597173144876324"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one class svm normalized data\n",
    "from sklearn import svm\n",
    "\n",
    "svc1 = svm.OneClassSVM(kernel=\"rbf\", gamma=2 ** 9, nu = 0.1)\n",
    "\n",
    "inliers = norm_data.loc[norm_data['Class'] == 'normal',:].drop(['Class'], axis=1)\n",
    "outliers_flood = norm_data.loc[norm_data['Class'] == 'flooding', :].drop(['Class'], axis=1)\n",
    "outliers_slow = norm_data.loc[norm_data['Class'] == 'slowloris', :].drop(['Class'], axis=1)\n",
    "\n",
    "target_in = np.ones(len(inliers.index))\n",
    "target_out_flood = np.full(len(outliers_flood.index), -1.0)\n",
    "target_out_slow = np.full(len(outliers_slow.index), -1.0)\n",
    "target_all = np.concatenate([target_in, target_out_flood, target_out_slow])\n",
    "\n",
    "\n",
    "svc1.fit(inliers)\n",
    "# predicted_in = svc1.predict(inliers)\n",
    "predicted_out_flood = svc1.predict(outliers_flood)\n",
    "predicted_out_slow = svc1.predict(outliers_slow)\n",
    "# predicted_all = np.concatenate([predicted_in, predicted_out_flood, predicted_out_slow])\n",
    "\n",
    "# ac = metrics.accuracy_score(target_all, predicted_all)\n",
    "# ac_in = metrics.accuracy_score(target_in, predicted_in)\n",
    "ac_out_flood = metrics.accuracy_score(target_out_flood, predicted_out_flood)\n",
    "ac_out_slow = metrics.accuracy_score(target_out_slow, predicted_out_slow)\n",
    "\n",
    "print(ac_out_flood, ac_out_slow)\n",
    "predicted = cross_val_predict(svc1, inliers, target_in, cv=10)\n",
    "metrics.accuracy_score(predicted, target_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89947089947089942"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "kf.get_n_splits(inliers)\n",
    "p = np.empty(1, dtype=int)\n",
    "t = np.empty(1, dtype=int)\n",
    "svc1 = svm.OneClassSVM(kernel=\"rbf\", gamma=5, nu = 0.0001)\n",
    "for train_index, test_index in kf.split(norm_data):\n",
    "    \n",
    "    train_data = norm_data.iloc[train_index]\n",
    "    test_data = norm_data.iloc[test_index]\n",
    "    \n",
    "    inliers_train = train_data.loc[norm_data['Class'] == 'normal', :].drop(['Class'], axis=1)\n",
    "    \n",
    "#     outliers_flood = test_data.loc[norm_data['Class'] == 'flooding', :].drop(['Class'], axis=1)\n",
    "#     outliers_slow = test_data.loc[norm_data['Class'] == 'slowloris', :].drop(['Class'], axis=1)\n",
    "    inliers_test = test_data.loc[norm_data['Class'] == 'normal', :].drop(['Class'], axis=1)\n",
    "    \n",
    "    t1 = np.ones(len(inliers_test.index))\n",
    "#     t2 = np.full(len(outliers_slow.index), -1.0)\n",
    "#     t3 = np.full(len(outliers_flood.index), -1.0)\n",
    "    \n",
    "    t = np.append(t, t1)\n",
    "#     t = np.append(t, t2)\n",
    "#     t = np.append(t, t3)\n",
    "    \n",
    "    svc1.fit(inliers_train)\n",
    "    \n",
    "    p1 = svc1.predict(inliers_test)\n",
    "#     p2 = svc1.predict(outliers_slow)\n",
    "#     p3 = svc1.predict(outliers_flood)\n",
    "    \n",
    "    p = np.append(p, p1)\n",
    "#     p = np.append(p, p2)\n",
    "#     p = np.append(p, p3)\n",
    "    \n",
    "metrics.accuracy_score(p, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.05429156e-321   1.00000000e+000   1.00000000e+000 ...,\n",
      "   1.00000000e+000   1.00000000e+000  -1.00000000e+000]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
